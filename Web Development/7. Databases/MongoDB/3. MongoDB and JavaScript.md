- [MongoDB URI](#mongodb-uri)
- [Connecting to MongoDB](#connecting-to-mongodb)
  - [MongoClient](#mongoclient)
  - [Connecting to a Specific Database](#connecting-to-a-specific-database)
  - [Connecting to a Collection](#cnnecting-to-a-collection)
- [Async/Await](#asyncawait)
- [Basic Reads](#basic-reads)
  - [`findOne()`](#findone)
  - [`find()`](#find)
- [Cursor Methods and Aggregation Equivelants](#cursor-methods-and-aggregation-equivelants)
  - [Limiting Results](#limiting-results)
  - [Sorting Results](#sorting-results)
  - [Skipping Results](#skipping-results)
  - [Paging](#paging)
- [Basic Aggregation](#basic-aggregation)
- [Basic Writes](#basic-writes)
  - [`insertOne()`](#insertone)
  - [`insertMany()`](#insertmany)
  - [Upsert](#upsert) 
- [Write Concernts](#write-concerns)
- [Basic Updates](#basic-updates)
  - [`updateOne()`](#updateone)
  - [`updateMany()`](#updatemany)

# MongoDB URI

URI stands for **U**niform **R**esource **I**dentifier, and it will look very similar to a URL. URIs are used to connect web apps with MongoDB and will define everything about the connection (username, password, and options). We will generally us an `srv` (service) string that looks like this:

```
mongodb+srv://<username>:<password>@<host>/<database>
```

- `mongodb+srv` is the prefix to our URI that lets us know that we will be connecting to a spceial `srv` record in MongoDB
- `username` and `password` are our credentials to access the database
- `host` is the host name of the `srv` (service) record
- `database` is the database in our cluster that we want to connect to

Any other opitons are specified in the same way URL queries are specified.

# Connecting to MongoDB

## MongoClient

To connect to our database server, we use the `MongoClient` objects `connect()` method. The `connect()` method takes two arguments. The first is the database server URI that we are connecting to (this should be stored in the `.env` file to help keep it protected), and the second argument is an object that defines the options of our connection.

```js
client = await MongoClient.connect(process.env.DB_URI, {
  connectTimeoutMS: 200,
  retryWrites: true,
  useNewUrlParser: true,
})
```

The options defiend above tells the connection to timeout after 200 milliseconds, retry writes, and use the new url parser in order to be future compatible, so this client will have the default connection parameters.

We can examine all the options of our connect by the `option` object

```js
const options = client.s.options;
// See if the connection is SSL enabled, 
// which it should be if we are using an srv string to connect to the database
options.ssl // true
```

See all the options for the client in the [documentation](https://www.mongodb.com/docs/drivers/node/current/fundamentals/connection/connection-options/)

## Connecting to a Specific Database

Once connected to the database server, we can set variables to specific databases in our database server to interact with them using the `.db()` method.

```js
const myDB = client.db(process.env.MY_DB); 
//Database name string should also be storned in the .env file
```
## Cnnecting to a Collection

Then, we can create direct connections with a collection within our database by using `.colleciton`

```js
const collection = myDB.collection("collection");
```

# async/await

When using the MongoDB driver with Node.js, it's important to use asynchronous programming. The cleanest way to do this is by implementing async/await

To use async/await, we need to mark our function as async, as can be seen in the following test function. This then let's us use the `await` keyword for Promises. Behind the scenes, you can think of it as attaching the `.then()` part to a promise and returning that value. 

What about the `.catch()` part? That's handled by a catch block. An important thing to remember is to always surround `await` statements with a try/catch block.

Let's see an example.

```js
test("Async/Await", async () => {
  try {
    let { title } = await movies.findOne({
      title: "Once Upon a Time in Mexico",
    })
    let { cast } = await movies.findOne({
      title: "Once Upon a Time in Mexico",
    })
    expect(title).toBe("Once Upon a Time in Mexico")
    expect(cast).toContain("Salma Hayek")
  } catch (e) {
    expect(e).toBeNull()
  }

  /**
  * We've used destructuring here to lift the title and cast keys from the
  * returned document. It would have been more efficient to do a single
  * `findOne` operation and grab the title and cast at the same time, but I
  * wanted to demonstrate that multiple awaits can be within the same
  * try/catch block.
  */
})
```

Once we've connected to a collection, we can start performing CRUD operations.

# Basic Reads

## `findOne()`

The `findOne()` method finds one random document that matches our query and returns it for us.

```js
let result = await movies.findOne({ cast: "Salma Hayek"});
```

Here, we are finding one document in our `movies` collection where one of the cast memvers is Salma Hayek.

 **If no document is found, the returned value is `null`**.

As you can see, the `findOne()` method works just like our MQL querying from the console from the previous notes page, but now we can store the results and use it.

Since our queries work just like MQL in the cosole, we can also use projections to only return specific field from our document

```js
let result = await movies.findOne(
  { cast: "Salma Hayek" },
  { projection: { title: 1, year: 1 } },
)
```

This will return an object with 3 keys: `title`, `year`, and `_id`.

## `find()`

To find all documents that match our query, we can use the `.find()` method.

Say we wanted to return all documents form the movies collection where both Johnny Depp and Salma Hayek were in the cast. Then our query would look like this:

```js
let result = await movies.find({
  cast: { $all: ["Salma Hayek", "Johnny Depp"] },
})
```

Note how similar it is to quering in the console. As you can see, we can still use MQL operators like `$all`

The `.find()` method returns a cursor object, and to access the documents in a cursor we need to use the `.next()` method or use the `.toArray()` method.

`.next()` returns the next result in the cursor and resolves to `null` if there are no more results.

# Cursor Methods and Aggregation Equivelants

## Limiting results

To limit the number of results returned in a cursor, we can use the `.limit(x)` method, where `x` is the number of results we want to return. Here, we are finding movies directec by Sam Raimi, but limiting the incoming results to only 2.

```js
const limitedCursor = movies
  .find({ directors: "Sam Raimi" }, { _id: 0, title: 1, cast: 1 })
  .limit(2)
```

We can also use the `$limit` token to limit the number of results in an aggregation pipeline. The following code block achieves the same result as our above code block when used as our search query.

```js
const limitPipeline = [
  { $match: { directors: "Sam Raimi" } },
  { $project: { _id: 0, title: 1, cast: 1 } },
  { $limit: 2 },
]
```

## Sorting Results

We can sort our results with the `.sort()` method. This allows us to define by which field we want our data sorted, in ascending or descending order. By default, results are ordered in "natural" order, which has no particular structure.

The following will sort our returned data by the `year` value in ascending order

```js
const sortedCursor = movies
  .find({ directors: "Sam Raimi" }, { _id: 0, year: 1, title: 1, cast: 1 })
  .sort([["year", 1]])
```

We can also sort within a pipeline using the `$sort` token.

```js
const sortPipeline = [
  { $match: { directors: "Sam Raimi" } },
  { $project: { _id: 0, year: 1, title: 1, cast: 1 } },
  { $sort: { year: 1 } },
]
```

## Skipping results

If we want to, we have the ability to skip results by using the `.skip(x)` method, where `x` is the number of results we want to skip. These skipped results will not be returned, but everything after that is returned. So if we wanted to skip the 5 oldest movies in our results, we could sort by `year` in ascending order, then use `.skip(5)`

```js
const skippedCursor = movies
  .find({ directors: "Sam Raimi" }, { _id: 0, year: 1, title: 1, cast: 1 })
  .sort([["year", 1]])
  .skip(5)
```

We can also do this in the pipeline by using the `$skip` token.

```js
const skippedPipeline = [
  { $match: { directors: "Sam Raimi" } },
  { $project: { _id: 0, year: 1, title: 1, cast: 1 } },
  { $sort: { year: 1 } },
  { $skip: 5 },
]
```

## Paging

We can use a combination of `.limit()` and `.skip()` to create paging where only a certain number of results are used per page.

```js
const displayCursor = cursor.limit(moviesPerPage).skip(page * moviesPerPage);
```

# Basic Aggregation

Aggregation is a pipeline and pipelines are composed of stages (broad units of work). Within stages, expressions are used to specify individual units of work. Expressions are fuctions and can be used in various programming languages.

The Compass (Free) software produced by MongoDB. In it, we can build aggregation pipelines and export them to various programming languages.

We can build stages, set them to variables, put them in an array, then pass them to the `.aggregate()` method to create and use an aggregation pipeline.

```js
// Creating the aggregation stages
const matchStage = { $match: filters }
const sortStage = { $sort: { "tomatoes.viewer.numReviews": -1 } }
const countingPipeline = [matchStage, sortStage, { $count: "count" }]
const skipStage = { $skip: moviesPerPage * page }
const limitStage = { $limit: moviesPerPage }
const facetStage = {
  $facet: {
    runtime: [
      {
        $bucket: {
          groupBy: "$runtime",
          boundaries: [0, 60, 90, 120, 180],
          default: "other",
          output: {
            count: { $sum: 1 },
          },
        },
      },
    ],
    rating: [
      {
        $bucket: {
          groupBy: "$metacritic",
          boundaries: [0, 50, 70, 90, 100],
          default: "other",
          output: {
            count: { $sum: 1 },
          },
        },
      },
    ],
    movies: [
      {
        $addFields: {
          title: "$title",
        },
      },
    ],
  },
}

// Putting all the stages in an array to create the pipeline
const queryPipeline = [
  matchStage,
  sortStage,
  skipStage,
  limitStage,
  facetStage,
]

// Passing the pipeline to the `.aggregate()` method
const results = await (await movies.aggregate(queryPipeline)).next()
```

# Basic Writes

## `insertOne()`

When connected to a colleciton in our database, we can write documents to the collection using the `insertOne()` function.

```js
let insertResult = await collection.insertOne({
  title: "Fortnite",
  year: 2018
})
```

When we insert a document, we get an `insertOneWriteOpResult` object. One of the properties of this object is `result` where `result.n` is the total number of documents inserted. This is helpful for running test to ensure the correct number of documents were created during the operation.

It also contains an `insertedCount` key, which should be he same as `n`

Another property is `insertedId`. If we don't specify an `_id` when we write to the database, MongoDB will insert one for us and retun this to us here. That way we can use the id of the document we just inserted to find it in the database.

If we try to insert a document with an `_id` that already exists in the collection, we will get an error message stating that we tried to insert a duplicate key.

## `insertMany()`

If we want to insert more than one document at a time, we can use the `insertMany()` method.

```js
let megaManYears = [
  1987,
  1988,
  1990,
  1991,
  1992,
  1993,
  1995,
  1996,
  2008,
  2010,
]

// Creating documents to insert based on the megaManYears array above
let docs = megaManYears.map((year, idx) => ({
  title: `Mega Man ${idx + 1}`,
  year,
}))

// now let's insert these into the database
let insertResult = await videoGames.insertMany(docs)
```

Just like `insertOne()` we get a result object back that has information ike the number of documents inserted and the inserted `_id`s

## Upsert

What happens if we want to insert a document, but we're not sure if it's already there in the database? We could do a find to check, but that's inefficient when we have the ability to upsert.

```js
let upsertResult = await collection.updateOne(
  // this is the "query" portion of the update
  { title: "Call of Duty" }
  // this is the update portion
  {
    $set: {
      title: "Call of Duty",
      year: 2003
    }
  },
  // This is the options document where we can specify options of our update
  // If we set upsert: true the document will create a new document if
  // the query doesn't find a valid document to match our query
  { upsert: true }
)
```

This will also return a `result` object with information like `nModified` to tell us how many documents were modified and `upserted` which contains an `_id` and `index`. If the document we were looking for existed, we won't get an `upserted` key in the `result` object, since something was updated, not created.

# Write Concerns

The `writeConcern` is how many nodes applied the write by the time an acknowledgement is sent back to the client. When only one node applies the write and sends back an acknowledgement, we have `writeConcern: {w: 1}`, which is the default in MongoDB. When no `writeConcern` is defined in our request, MongoDB will automatically use `writeConcern: {w: 1}` and only await acknowledgement form one node in the cluster.

If we use `{w: majority}`, then the acknowledement will only be sent back to the client when the majority of nodes in the cluster have written the data. So, if we have 3 nodes in our cluster, two nodes must complete the write before an acknowledgement will be sent back to the client.

`w: majority` is more durable, but takes longer than `w: 1`. However, it will not increase the stress on our database to use `w: majority`. It's useful for ensuring vital writes are majority-committed, like when a user is creating a count.

`w` can be any any number and it will specify the number of nodes that must complete the write before acknowledgement is sent. If the number is higher than the amount of nodes in the cluster, we will recieve an error.

`w: 0` does not request acknowledgement that any nodes applied the write. It's a "fire-and-forget" opertaion. It's the fasted `writeConcern` level, but the least durable. This can be useful for testing networks for errors and socket exceptions. This can also be very useful for writes that happen frequently and aren't very important. Like a computer that sends non-important information every two minutes to the database. It's okay if some things get lost.

# Basic Updates

There are two different updates we can use: `updateOne()` and `updateMany()`. Both options return an `UpdateResult` object.

## `updateOne()`

We can update a single document in a collection with `updateOne()`. This method takes a query predicate (to match a document) and a JSON object of one or more update operators to describe how to update that document.

If the predicate matches more than one document, `updateOne()` will only update the first document it finds, which can be unpredictable. So, make sure that the query predicate only matches the document you wish to update.

We can use the `$set` operator to set a new value for a field of our document and we can use `$inc` to modify the numerical value of fields.

```js
const updateOneResult = await theaters.updateOne(
  // Match to a document where theaterId is 8
  { theaterId: 8 },
  {
    // Set street1 to a new value
    $set: { "location.address.street1": "14161 Aldrich Ave S" },
    // Modify the numerical values of the geo coordinates
    $inc: {
      "location.geo.coordinates.0": -10,
      "location.geo.coordinates.1": -25,
    },
  },
)
```

From here we have our `UpdateResult` object that has some usefull fields. We can access `UpdateResult.modifiedCount` to see how many documents where updated and `UpdateResult.matchedCount` to see how many documents matched our update query.

## `updateMany()`

We can also update multipe documents in a colleciton at once by using `updateMany()`. Just like `updateOne()`, this methods takes a predicate and a JSON object containing one or more operators. 

However, `updateMany()` will update all documents matched according to updates we specify in the JSON object. Other than that, it works exactly the same as `updateOne()`.

# Basic Deletes

We can remove documents from collections using the `deleteOne()` and `deleteMany()` methods.

## `deleteOne()`

`deleteOne()` accepts a query filter that matches the document you want to delete. If you don't include a query filter, MongoDB will match a delete the first document it finds.

```js
try {
  await connectToDatabase()
  let result = await accountsCollection.deleteOne(documentToDelete)
  result.deletedCount === 1
    ? console.log("Deleted one document")
    : console.log("No documents deleted")
} catch (err) {
  console.error(`Error deleting documents: ${err}`)
} finally {
  await client.close()
}
```

## `deleteMany()`

`deleteMany()` works on the same principle. It deletes all documents that mathc the query filter.

```js
try {
  await connectToDatabase()
  let result = await accountsCollection.deleteMany(documentsToDelete)
  result.deletedCount > 0
    ? console.log(`Deleted ${result.deletedCount} documents`)
    : console.log("No documents deleted")
} catch (err) {
  console.error(`Error deleting documents: ${err}`)
} finally {
  await client.close()
}
```

# Transactions

A transaction is a group of database actions that will be completed as a unit or not at all; either they all succeed or nothing happens. This is called **atomicity**. Uses for this would be taking payment in a mobile app or take an item out of inventory and putting into a shopping cart.

Transactions are done in the following steps:

1. Start a client session
2. Define the transaction options (optional)
3. Define the sequence of operations to perform inside the transaction
4. Release/close resources used by the transaction.

By default, a multi-document transaction has a 60-second time limit. Meaning Mongo DB will automatically cancel any transactions that take more than 60 seconds.

Let's see how to create a transaction that transfers some money from one account to another, step-by-step, with code examples:

1. Create variables to be used in the transaction

```js
// Collections
const accounts = client.db("bank").collection("accounts")
const transfers = client.db("bank").collection("transfers")

// Account information
let account_id_sender = "MDB574189300"
let account_id_receiver = "MDB343652528"
let transaction_amount = 100
```

2. Start a new Session

```js
const session = client.startSession();
```

3. Begin a transaction with the `withTransaction()` method on the session.

```js
const transactionResults = await session.withTransaction(async () {
  // Operations will go here
})
```

4. Update the `balance` field of the sneder's account by decrementing the `transaction_amount` from the `balance` field.

```js
const senderUpdate = await accounts.updateOne(
  { account_id: account_id_sender },
  { $inc: { balance: -transaction_amount } },
  { session }
)
```

5. Update the `balance` field of the receiver's account by incrementing the `transaction_amount` to the `balance` field.

```js
const receiverUpdate = await account.updateOne(
  { account_id: account_id_receiver },
  { $inc: { balance: transaction_amount } },
  { session }
)
```

6. Create a transfer document and insert it into the `transfers` collection.

```js
const transfer = {
  transfer_id: "TR21872187",
  amount: 100,
  from_account: account_id_sender,
  to_account: account_id_receiver
}

const insertTransferResult = await transfers.insertOne(transfer, { session })
```

7. Update the `transfers_complete` array of the sender's account by adding the `transfer_id` to the array

```js
const updateSenderTransferResults = await accounts.updateOne(
  { account_id: account_id_sender },
  { $push: { transfers_complete: transfer.transfer_id } },
  { session }
)
```

8. Update the `transfers_complete` array of the receiver's account by adding the `transfer_id` to the array.

```js
const updateReceiverTransferResults = await accounts.updateOne(
  { account_id: account_id_receiver },
  { $push: { transfers_complete: transfer.transfer_id } },
  { session }
)
```

9. Log a message regarding the success or failure of the transaction.

```js
if (transactionResults) {
  console.log("Transaction completed successfully.")
} else {
  console.log("Transaction failed.")
}
```

10. Catch any errors and close the session.

```js
} catch (err) {
  console.error(`Transaction aborted: ${err}`)
  process.exit(1)
} finally {
  await session.endSession()
  await client.close()
}
```
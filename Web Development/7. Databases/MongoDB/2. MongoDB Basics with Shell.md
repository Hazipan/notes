# Contents

1. [Connecting to our Database](#connecting-to-our-database)
2. [Importing and Exporting Data](#importing-and-exporting-data)
3. [Querying in the Console](#querying-in-the-console)
4. [Adding Documents](#adding-documents)
5. [Updating Data](#updating-data)
6. [Deleting Documents and Collection](#deleting-documents-and-collections)
7. [Comparison Operators](#comparison-operators)
8. [Logic Operators](#logic-operators)
9. [Expressive Query Operator](#expressive-query-operator)
10. [Array Operator](#array-operator)
11. [Projection and `$elemMatch`](#projection-and-elemmatch)
12. [Querying Arrays and Sub-Documents](#querying-arrays-and-sub-documents)
13. [Aggregation Framework](#aggregation-framework)
14. [`sort()` and `limit()`](#sort-and-limit)
15. [Indexes](#indexes)
16. [Intro to Data Modeling](#intro-to-data-modeling)
17. [Upsert](#upsert)
18. [Certificate](#certificate)

# Connecting to our Database

When connecting to our cloud database, we use a URI string with the following format

```bash
"mongo+srv://user:password@clusterURI.mongodb.net/database"
```

To connect to our database in a shell, we can use the following command

```bash
mongo "mongo+srv://user:password@clusterURI.mongodb.net/database" --username <username>
```

Once connected, we will be in the MongoDB shell, which is a fully functioning JavaScript interpreter and we can interact with our database without a GUI.

# Importing and Exporting data

## Exporting

To expot data as a JSON file, we use the `mongoexport` command

```bash
mongoexport --uri "<Atlas Cluster URI>"
            --colleciton=<collection name>
            --out=<filename>.json
```

To export out data as BSON, we use `mongodump`

```bash
mongodump --uri "<Atals Cluster URI>"
```

## Importing Data

To import via BSON, we navigate to our binary data dumb and use `mongorestore`

```bash
mongorestore --uri "<Atlas Cluster URI>" --drop dump
```

To import JSON data, we use `mongoimport`

```bash
mongoimport --uri "<Atlas Cluster URI>" --drop=<filename>.json
```

The `--drop` parameter drops the database where we specify and replaces it with our imported data and it must be used.

When importing JSON data, we can specify a `--collection` parameter. If we don't define it, then it defaults to the name of the file we are importing.

# Querying in the console

Once we are connected in our console, we can begin querying the database. To see what databases are available, we can use the `show dbs` command. This will show a list of all the databases in the cluster and their size.

To select a specific database, use the `use <database_name>` command. This will connect us to a specific database. Then we can see all the collections in that database with the `show collections` command.

To query a collection of our selected database, we use the `db.<collection_name>.find(<query>)` command.

```bash
db.zips.find( {"state": "NY"} )
```

This will show up to 20 documents. To see the next page of documents, we use the `it` command. The `it` command iterates through the `cursor`. The `cursor` is an object that the find command returns and it is a `pointer` to a result set of a query, which is the direct address of the memory location.

To know how many documents match our query, we can append the `.count()` command to our `.find()` command

```bash
db.zips.find( {"state": "NY" }).count()
```

To make our results more readable, we can use the `.pretty()` directive.

```bash
db.zips.find( {"state": "NY" }).pretty()
```

If we issue the `.find()` command with no query, we recieve 20 documents from the data in no particular order.

We can also get a random, singular document by using the `.findOne()` command. The below code snippet will return one random document that matches our query. We could also pass no query, and just get a radom document. This is greate for getting an idea of the shape of the documents in a specific colleciton.

```bash
db.zips.findOne( {"state": "NY" }).pretty()
```

# Adding Documents

All documents must have a unique `_id`. When you create a document, this field is automatically created with a value that is an `ObjectId` datatype. This is a MongoDB special datatype that ensures a completely unique id is created. However, you can use any value you want, but make sure that it would be unique! The `_id` vied is required for all documents.

To create new documents, we can use the `.insert()` command.

```bash
db.<collection_name>.insert(<document object>)
```

Generally, don't specify an `_id` field, since it will be auto generated for us with a unique `ObjectId` value. 

MongoDB does have schema validation functionality that allows us to enforce a specific document structure, but we won't learn that here.

We can also insert multiple documents at once with `.insert()` and passing an array of documents

```bash
db.<collection_name>.insert([<document object>, <document object>, ...])
```

If you specify a collection that doesn't exist yet, the collection will be created! Same thing if you try to connect to a database that doesn't exist in your cluster. ***So, be careful not to misspell a collection or database name***

# Updating Data

To update documents in the mongo shell, we will use the MQL query language, which is MongoDB's custom query syntax. There are two methods to update documents: `updateOne()` and `updateManu()`. `updateOne()` works like `findOne()` and `updateMany()` works like `find()`.

Both function take two arguments. The first is the query, and the second is the update that needs to happen.

```bash
db.zips.updateMany({"city", "HUDSON", {"$inc": {"pop": 10}}})
```

Here, we used the `$inc` MQL update operator. This tells MongoDB that the specified fields will be increased by the value provided. In this case `pop` is increased by `10` for all documents matching the query `{"city": HUDSON}`. We can change multiple values by separating them with commas.

## Update Operators

- `$inc` increases the field by the value
- `$set` sets the filed to the value
	- Be careful! If you misspell a field and issue an update, the field will be created
- `$push` adds an element to an array field. 

See [all available update operator](https://docs.mongodb.com/manual/reference/operator/update/#id1) in the documentation.

The dollar sign has a few uses. It precedes MQL operators and aggregation pipeline stages. It is also used for accessing field values.

# Deleting Documents and Collections

To delete documents, we can use `deleteOne()` and `deleteMany()`, which work similarily to `findOne()` and `find()` as well. `deleteOne()` is only good to use if you are querrying for the specific `_id` to ensure that we delete the correct document. 

To remove a **collection**, we use the `.drop()` function.

```bash
db.<collection_name>.drop()
```

If you remove all collections within a database, the database will be removed as well.

# Comparison Operators

 - `$eq` - equals to
 - `$ne` - not equals to
 - `$gt` - greater than
 - `$lt` - less than
 - `$gte` - greater than or equal to
 - `$lte` - less than or equal to

All of these are used in queries and use the following syntax:

```
{ <field>: { <operator>: <value> } }
```

# Logic Operators

- `$and`
- `$or`
- `$nor`

```
{<operator: [{statement1}, {statement2},...]}
```

- `$not`

```
{$not: {statement}}
```

The `$and` operator is already present by simply querying multiple field at once. It is *implicit*. The only time you need to explicitly use `$and` is when you are chaining logic operators together.

# Expressive Query Operator

The expressive opperator, `$expr`, allow sthe use of aggregation expressions within the query language. It also lets us use variables and conditional statements.

```
{$expr: {<express>}}
```

We can use the dollar sign (`$`) to access a field to compare values within the same document.

```
{$expr: {$eq: ["$start station name", "$end station name"]}}
```

This will return all documents where the `start station name` and the `end station name` have the same value.

The `$expr` operator uses the Aggregation syntax.

```
{<operator>: {<field>,<value>}}
```

```
{"$expr": {
	"$and": [
		{"$gt": ["$tripduration", 1200]},
		{"$eq": ["$end station id", "$start station id"]}
	]
}}
```

# Array Operator

- `$push` adds an elment to an array and turns a field into an array field it if ws previously a different type.

To query for specific elements within an array field, we can use `$all`. It will return any docmunts that have at least the defind values of the `$all` operator.

```
{<array_field>: {"$all": [<value>, <value>, ...]}}
```

We can use the `$size` operator to filter by exact array length.

```
{<array_field>: {"$size": <number>}}
```

# Projection and `$elemMatch`

## Projection

When we query the database, sometimes we get a lot of data in one query, and it doesn't all fit on the screen. Luckily, we can use the second argument in the `.find()` method, the projection perameter.

```
db.listingAndReviews.find({"amenitities" {$size: 20, $all: ["Internet"]}}, {"price": 1, "address": 1}).pretty()
```

This will show only the `_id`, `"price"`, and `"address"` fields of the documents that match our queries because we specified the `"price"` and `"address"` fields in or second argument.

The projection parameter allows us to specify which fields we want to include/exclude. A projection is the field name followed by a `1` or a `0`. `1` meaning include and `0` meaning exclude. Only use `1`s or `0`s, not both in a projection argument.

```
db.<collection>.find({ <query> }, { <projection >})
```

## `$elemMatch`

`$elemMatch` is an array operator that lets us query nested documents. We can use it in either the first or second argument of the `.find()` method.

```
{<array field> : { $elemMatch: { <field>: <value>}}}
```

# Querying Arrays and Sub-Documents

To query document fields from a sub-document, we can use dot notation.

```
db.trips.findOne({"start_station_location.type": "Point"})
```

This will return one document that has a sub-document with a `"type"` field with the value of `"Point"`. This can be used to go as deep as we need into sub-documents

```
db.companies.find({"relationships.0.person.last_name": "Zuckerberg}. {"name": 1}).pretty()
```

In the above query, we used a `0`, which is accessing the 0th index of an array. That is how you can access specific indexes of arrays, by using dot notation and specific indexes.

# Aggregation Framework

The aggregation framerok, in its simplest, is just another way to query data in MongoDB. Here's some example syntax:

In normal MQL:

```
db.listingsAndReviews.find(
		{"amenities" "Wifi"},
		{"price": 1, "address": 1, "_id": 0}).pretty()
```

Using the aggregation framework:

```
db.listingAndReviews.aggregate([
	{$match: {"amenities": "Wifi"}},
	{$project: {"price": 1, "address": 1, "_id": 0}}])
```

We use `.aggregate` instead of `.find` because the aggregation framework will also let us group or modifiy our data in someways instead of just find. We can also calculate using `.aggregate`.

Notice that `.aggregate` takes an array. This is because the aggregatin framework works as a pipe line where the order of actions matters and the actions are performed in the order they are listed. In this case, the `$match` stage goes and then the `$project` stage goes. `$match` looks through all the documents and only lets documents that match the query through to the next stage of the pipeline. `$project` filters out documents fields to only show us the data fields we want. In this case, we will see the `price` and `address` field of all documents that have `Wifi` in the `amenities` field. So we are *matching* a query, then *projecting* specific feilds.

The aggregation framework allow us to create complex pipelines that lets us to do a lot with our data. With MQL we can filter and update data, but with the aggregation framework we can group, compute, and reshape data.

***Whenever we use non-filtering stages we are not modifying the original data. It only works on the data in the cursor***

## Aggregation Stages

- `$match` filters our documents like a reqular query.
- `$project` projects document fields we wish to see (or hide)
- `$group` takes an incoming stream of data and siphons it into multiple distinct reservoirs.

```
{ $group:
	{
		_id: <expression>, // group by expression
		<field1>: { <accumulator1> : <expression1> }.
		...	}}
```

Essentially, `$group` allows us to create new data sets by using data from the given sets. Consider this:

```
db.listingAndReviews.aggregate([
	{$project: {"address": 1, "_id": 0},
	{$group: {_id: "address.country",
						"count": {$sum: 1}}}
	])
```

This aggregation first projects our data so we only have the `address` field of the documents. Then, with `$group`, we are creating a new dataset by grouping the data from the previous set by their `address.country`. The `"count": {$sum: 1}` syntax will add `1` to the `count` field for every data point that has the same `address.country`. Using `$sum` with `$group` will add the value of the specified field to the given new field (in this case `count`) for every item that matches the `$group` argument (the value for `_id`). Here, we are just adding `1` for each item, but we could add specific fields together. If the documents had a `price` filed we could use `"count": {$sum: $price}`.

More about the aggregation framework can be found in the Aggregation Framework course

# `sort()` and `limit()`

`sort()` and `limit()` allows us to get our data in the order and quantity we are looking for. 

The `sort()` method takes one or more fields and sorts the documents by those field in either ascending or descending order by setting the field to 1 (for ascending) or -1 (for descending). The following sorts zip code documents from lowest to highest population, and then descending order (Z -> A) for the city name.

```
db.zips.find().sort({"pop": 1, "city": -1})
```

The `limit()` funciton takes a number and only retruns that amount of documents. So, `limit(1)` would return the top document of the query.

***MongoDB will assume to sort before it limits regardless of how you type it.***

# Indexes

From here, we should try to make our queries more effecient, and the most impactful way is to add indexes to suport our queries. In a database, an index is a special data structure that stores a small portion of the collection's data in an easy to traverse form. You should build an index for common queries.

```
db.trips.createIndex({"birth year": 1})
```

The above code creates an index of the `birth year` field in ascending order. Now, when we query that same field, MongoDB will use the index for faster results.

```
db.trips.find({"birth year": 1989})
```

We can also create compound index that indexes multiple fields together.

```
db.trips.createIndex({"start station id": 1, "brith year": 1})
```

The above will create an index that compounds the `start station id` values and `birth year` values. This type of index is great for queries that are often used together.

There's a hell of a lot more about indexes to learn, but that will not be covered here.

# Intro to Data Modeling

Data modeling is making decisions about how your data should work. It is a way to organize fields in a document to support your application performance and querying capabilities. **Rule of thumb**: *data is stored in the way that it is used*. Another consideration is how the data will be queried. The most useful data and data needed the most often by your users should be easiest to querry. Regularly querried together means the data should be stored together.

# Upsert

Everything we've learned about how to locate a document can be used to modify the document.

```
db.collectin.updateOne({<query to locate>}, {<update>})
```

For update functions, the first argument is the query to locate the document and the second argument is how to update the document. We can also add a thrid argument: `{"upsert":true}`.

Upsert is defaulted to `false`. When `true`, the command will either update the document if there is a match to the query or insert a new document if there is no match.

# Certificate

See my [certificate of completion](https://university.mongodb.com/course_completion/943ed486-a948-4ad1-874c-e37500c2a166/printable?format=img) from MongoDB!
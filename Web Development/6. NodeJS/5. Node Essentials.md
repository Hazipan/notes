The Events Module
	• Node is described as having event-driven architecture
	• In traditional imperative programming, we give the computer a series of instructions to execute in a pre-defined order.
		○ In contrast, web applications are written to handle situations without knowing exaclty when things will occur
		○ When Node was created, it applied that same concept of event-driven principles to the back-end environment
	• Node provieds an EventEmitter class that we access through the events core module
		
		// require the 'events' module
		const events = require("events");
		
		// create an instance of the EventEmitter class
		let myEmmiter = new events.EventEmitter();
		
	• Each event emitter instance has a .on() method which assigns a listener callback function to a named event
		○ The .on() method takes as its first argument the name of the event as a string and, as its second argument, the listener callback funciton
	• Each event emitter instance also has a .emit() method which announces a named event has occurred
		○ The .emit method takes as its first argument the name of the event as a string and, as its second argument, the data that should be passed into the listener callback function

		let newUserListener = (data) => {
		  console.log(`We have a new user: ${data}.`);
		};
		 
		// Assign the newUserListener function as the listener callback for 'new user' events
		myEmitter.on('new user', newUserListener)
		 
		// Emit a 'new user' event
		myEmitter.emit('new user', 'Lily Pad') //newUserListener will be invoked with 'Lily Pad'
		
User Input/Output
	• The console.log() method is a "thin wrapper" on the .stdout.write() method of the process object
		○ stdout stands for standard output
	• In Node, we can receive user input thorugh the terminal by using the stdin.on() method on the process object
		
		process.stdin.on("data", (userInput) => {
		  let input = userInput.toString();
		  console.log(input);
		});
		
		○ Here, we can use .on() because under the hood, process.stdin is an instance of EventEmitter
			§ When a user enters text into the terminal and hits enter, a "data" event will be fired and our anonymous listener callback will be invoked
			§ The userInput we receive is an instance of the Node Buffer class, so we convert it to a string before printing
		
		let {testNumber} = require('./game.js');
		
		process.stdout.write("I'm thinking of a number from 1 through 10. What do you think it is? \n(Write \"quit\" to give up.)\n\nIs the number ... ");
		
		process.stdin.on("data", (userInput) => {
		  let input = userInput.toString().trim();
			testNumber(input);
		});
		
		○ Outputs the starting message, then expects user input. On input, it stores the input (trimming of an escape character at the end of the object) and runs a function with it. The process doesn't end until process.exit() is run from game.js, when the user quites or guesses correctly
			§ Differs from console.log() which is done immediately
		○ Also could be written like this (more readable):
		
		let {testNumber} = require('./game.js');
		
		process.stdout.write("I'm thinking of a number from 1 through 10. What do you think it is? \n(Write \"quit\" to give up.)\n\nIs the number ... ");
		
		let playGame = (userInput) => {
		  let input = userInput.toString().trim();
			testNumber(input);
		};
		
		process.stdin.on('data', playGame);
		
The Error Module
	• Node's error module has all the standard JS errors:
		○ EvalError
		○ SyntaxError
		○ RangeError
		○ ReferenceError
		○ TypeError
		○ URIError
	• It also has the JS Error class for creating new error instances
		○ We can generate errors and throw then, and with sychronous code in Node, we can use error handling techniques such as try…catch statements
	• The error module is within the global scope, so no need to require it
	• Many asynchronous Node APIs use error-first callback funcitons that have an error as the first expected argument and the data as the second argument
		○ If the asynchronous task results in an error, it will be passed as the first argument in the callback funciton. If no error was thrown, the first argument will be undefined
		
		const errorFirstCallback = (err, data)  => {
		  if (err) {
		    console.log(`There WAS an error: ${err}`);
		  } else {
		    // err was falsy
		    console.log(`There was NO error. Event data: ${data}`);
		  }
		}
		
	• The reason asynchronous APIs don't use try…catch statement is because those do not work for asynchronous fuctions

The Buffer Module
	• The Node.js Buffer module is used to handle binary data
		○ The Buffer nodule is also within the global scope, so we don't need to import it
	• A Buffer object represents a fixed amount of memory that can't be resized
		○ Buffer objects are similar to an array of intergers where each element in the array represents a byte of data
		○ The Buffer ovject will have a range of intergers form 0 to 255 inclusive
	• The Buffer module provides a variety of methods to handle binary data:
		○ .alloc() creates a new Buffer object with the size specified as the first parameter. It takes 3 arguments
			1. Size: required. The size of the buffer
			2. Fill: optional. A value to fill the buffer with. Default is 0
			3. Encoding: optional. Default is UTF-8
			
			const buffer = Buffer.alloc(5);
			console.log(buffer); // -> [0, 0, 0, 0, 0]

		○ .toString() translates the Buffer object into a human-readable string. It accepts 3 optional arguments
			1. Encoding: Default is UTF-8
			2. Start: the byte offset to begin translating the Buffer object. Default is 0
			3. End: The byte offset to end translating in the Buffer object.
			
			const buffer = Buffer.alloc(5, "a");
			console.log(buffer.toString()); // -> aaaaa
			
		○ .from() creates a new Buffer object from the specified string, array, or buffer. It accepts 2 arguments
			1. Object: Required. An obect to fill the buffer with
			2. Encoding: Optional. Default is UTF-8
			
			const buffer = Buffer.from("hello");
			console.log(buffer) // -> [104, 101, 108, 108, 111]
			
		○ .concat() joins all buffer objects passed in an array into one Buffer object
			§ This comes in handy because a Buffer object cannot be resized
			§ It accepts 2 arguments
			1. Array: Required. An array containing buffer objects
			2. Length: Optional. Specifies the length of the concatenated buffer
			
			const buffer1 = Buffer.from('hello'); // -> [104, 101, 108, 108, 111]
			const buffer2 = Buffer.from('world'); // -> [119, 111, 114, 108, 100]
			const array = [buffer1, buffer2];
			const bufferConcat = Buffer.concat(array);
			 
			console.log(bufferConcat); // -> [104, 101, 108, 108, 111, 119, 111, 114, 108, 100]
			
The FS Module
	• All of the data on a computer is organized and accessed through a filesystem
		○ When using JS in the browser, it's important for a script to have only limited access to a user's filesystem
		○ This technique of isolating some applications from others is known as sandboxing
			§ Sandboxing protects users from malicious programs and invasions of privacy
	• In the back-end, less restricted interaction with a filesystem is essential
		○ The Node fs core module is an API for interacting with the fils system
		○ It was modeled after the POSIX standard for interacting with the filesystem
	• All methods available through the fs module have a synchronous and asynchronous version
		○ One method available is the .readFile() method, which reads data from a provided file
		○ The .readFile() method has 3 arguments
			1. A string containing the path to the file
			2. A string specifying the files coding (usually "utf-8" for text files)
			3. A callback funciton to be invoked when the asynchornous task of reading from the file system is complete
		
		const fs = require('fs');
		 
		let readDataCallback = (err, data) => {
		  if (err) {
		    console.log(`Something went wrong: ${err}`);
		  } else {
		    console.log(`Provided file contained: ${data}`);
		  }
		};
		 
		fs.readFile('./file.txt', 'utf-8', readDataCallback);
		
Readable Streams
	• Previously, we look at entire files all at once, but we won't usually do that
		○ Data is usually processed sequentially, in what is known as a stream
		○ Streaming data is often preferable since you don't need enough RAM to process all the data at once, nore do you need to have all the data on hand to begin processing it
	• One of the simplest uses of streams is reading and writing to files line-by-line
		○ To do this, we can use the .createInterface() method from the readline core module
			§ It returns an EventEmitter set to emit 'line' events
		
		const readline = require('readline');
		const fs = require('fs');
		 
		const myInterface = readline.createInterface({
		  input: fs.createReadStream('text.txt')
		});
		 
		myInterface.on('line', (fileLine) => {
		  console.log(`The line read: ${fileLine}`);
		});
		
Writeable Streams
	• We can also write to streams using fs.createWriteStream()
		
		const fs = require('fs')
		 
		const fileStream = fs.createWriteStream('output.txt');
		 
		fileStream.write('This is the first line!'); 
		fileStream.write('This is the second line!');
		fileStream.end();
		
The Timers Module
	• Sometimes, we want our code to be executed at a specified point in time
		○ This is what the timers module is fore
		○ It is also a global, so no need to import it
	• We've already seen some timer functions like setTimeout() and setInterval()
	• Node.js timer functions werk very similarly to how they work on the fron-end, but in Node they are added to the event loop
		○ This means that the timer functions are scheduled and put into a queue
		○ This queue is processed at every iteration of the event loop
		○ If a timer function is executed outside of a modle, the behavior will be randome
	• setImmediate() is often compared with setTimeout()
		○ When setImmediate() is called, it executes the specified callback functin after the current poll phase

# Important Core Modules

- `http` - launch a server,  send requests
- `https` - launch an SSL server
- `fs` - allows us to access the computer file system
- `path` - helps us create url paths
- `os` - helps us know about our machines os and specifications
		
# A Simple Server

A break down of a super simple http server:
		 
```JS
// Require the http core module so we can use it in our code
const http = require("http");
		
/* The createServer() method returns a server, so it needs to be stored so we can use it later.
- It requires a request listener function as a parameter, which we provide an an anonymous ES6 arrow funciion
- The request listener function must have a request object and a response object as parameters */
const server = http.createServer((req, res) => {
		
	/* This log line will log the request object anytime the server is requested.
	- Run this code, go to localhost:3000, then view the terminal to see the full request object. It's huge! */
	console.log(req);
});
		
/* The listen function for a server object puts the server into an event loop and hooks it into a port (the first argument) where the server can hear requests and send responses on that port 
- It can also take a hostname argument, a backlog argument, and a listeningListener argument*/
server.listen(3000);
```
		
# Node.js Program Lifecycle for the above program

1. Run the program (`node app.js`)
2. The script starts
3. The code is parsed, variables and functions are registered
4. The event loop begins. The event loop (from the `listen()` method) keeps running so long as event listeners are registered.

If we were to place `process.exit()` after the `console.log()` line, it would exit the program once the request object was logged to the terminal.

Node programs use the event loop concept to create single-threaded, efficient apps. So, the program doesn't have to stop and process on every single request. Instead, it only processes when an event happens.

There is multi-threading in the back depending on the hardware it's being run on

When looking at the request object, there's a ton of info. Some of the important fields are:

- `url` - will just be a `/` if loading just `localhost:3000`
- `method` - will be `GET`, it's the default method
- `headers` - meta data

# Sending Responses

The response object is mostly empty to begin. We fill it with data to send back to the client. Something that needs to be set when sending back a response is the content type header, and we change headers via the `.setHeader()` method on the response object
		
```JS
res.setHeader("Content-Type", "text/html");
// This tells the browser that the content we're sending back is HTML text
```

There are set headers that the browser understands. To learn more, reference the [MDN Documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers).

To send actual data back, we can use the `.write()` method on the response object. It works in chunks (line-by-line) to construct the response
		
```JS
res.write("<html>");
res.write("<head><title>My first page</title><head>");
res.write("<body><h1>Hello from the server!</h1></body>");
res.write("</html>");
```
		
This constructs an html document line by line. Obviously, this is ridiculous and cumbersome. We'll learn a far easier way to do this later. 

Once our response object is created and ready to go, we end it via the `.end()` funciton
		
```JS
res.end();
```
		
This completes the object and sends it to the client. If you try to change the response object after this function call, it will result in an error.

# Routing Requests

We can send the client various resources depending on their url. We access the requested url by parsing it.
		
```JS
const url = req.url;
```
		
From here we can use conditionals to handle various pathnames.
		
```JS
const http = require("http");
const server = http.createServer((req, res) => {
  // separate the url out for easy use
  const url = req.url;
  // If the url has no path (home page), return an html form
  if (url === "/") {
    res.setHeader("Content-Type", "text/html");
    res.write("<html>");
    res.write("<head><title>Enter Message</title><head>");
    // On submit, POST and send us to /message. Cuases the url to change, so the other html becomes diplayed
   // The actual POST method is unhandled right now
    res.write("<body><form action='/message' method='POST'><input name='message' type='text'><button type='submit'>Send</button></form></body>");
    res.write("</html>");
    return res.end();
  }
  res.setHeader("Content-Type", "text/html");
  res.write("<html>");
  res.write("<head><title>My first page</title><head>");
  res.write("<body><h1>Hello from the server!</h1></body>");
  res.write("</html>");
  res.end();
});
server.listen(3000);
```
		
# Redirecting

We can redirect a user by setting the `Location` header. Taking the previous code, we can create another conditional block that takes into account the url and the http method together. If the url is `/message` and the method is `POST`, we can make it create a file and redirect us to another page
		
```JS
// parse the method from the request
const method = req.method;
const url = req.url;
		
// If the url is /messages and the http method is POST, create a message.txt file with the content "DUMMY", set the status code to 302, and redirect us to / via setting the Location header
if (url === "/messages" && method === "POST") {
  fs.writeFileSync("message.txt", "DUMMY");
  res.statusCode = 302;
  res.setHeader("Location", "/");
  return res.end();
}
```

In the this code block, submitting the form sent us to the `/message` path and used the http `POST` method

# Parsing Request Bodies

Incoming data from a request is sent in a stream. A stream is an ongoing process where data is separated into chunks and processed by chunk as they become available until the stream is fully parsed. Think file uploading. It needs to be able to be done in chunks, otherwise nothing else could be done until the entire file is parsed. 

All requests are handled in streams in Node. You can't arbitrarily manipulate these chunks as they come in. We need to use something called a `Buffer`. A `Buffer` is a construct that can hold multiple chunks for us to work with before releasing them once we are done

When processing a `POST` request, we want to get all the data before setting the status code and the headers. We do this by registering an event listener to the request object via the `.on()` method. The `.on()` method has various event types we can use. To see them, hover over the `.on()` method that is called on a request object
		
```JS
const body = [];
req.on("data", (chunk) => {
  console.log(chunk);
  body.push(chunk);
});
```
		
This `.on()` method will continously fire until there is no more data to process. Once all the data has been parsed, an `end` event will happen, so we need to create an event listener for that event. Once the `end` event fires, we need to create a buffer that allows us to interact with all the chunks collected.
			
```JS
req.on('end', () => {
  // create a Buffer and add all our chunks to it
  // then change the data type to something we can use
  // we know the incoming data will be a string, so we make the buffer a string
  const parsedBody = Buffer.concat(body).toString() ;
  console.log(parsedBody);
})
```
		
If we combine this code with our previous code and type Hello World! as the form input, here is our output:
		
```
<Buffer 6d 65 73 73 61 67 65 3d 48 65 6c 6c 6f 2b 57 6f 72 6c 64 25 32 31>
message=Hello+World%21
```

It has a name (`message`) because our input had a name. It creates a key-value pair from the submitted form data. We could get just the message via `parsedBody.split('=')[1]`. If we have code that relies on the incoming data it must be placed inside the `end` event listener, otherwise the data is inaccesible.

Putting everything together:
		
```JS
const http = require("http");
const fs = require("fs");
// Create the server
const server = http.createServer((req, res) => {
  // parse out the url and method for later use
  const url = req.url;
  const method = req.method
  // Show the form at the home page
  if (url === "/") {
    res.setHeader("Content-Type", "text/html");
    res.write("<html>");
    res.write("<head><title>Enter Message</title><head>");
    // On submit, redirect to /message using the POST method
    res.write("<body><form action='/message' method='POST'><input name='message' type='text'><button type='submit'>Send</button></form></body>");
    res.write("</html>");
    return res.end();
  }
  // if url is /message and method is POST
  if (url === "/message" && method === "POST") {
	  // Process the incoming data in chunks, and overwrite the input to the message.txt file
    const body = [];
    req.on('data', (chunk) => {
      console.log(chunk);
      body.push(chunk);
    });
    req.on('end', () => {
      const parsedBody = Buffer.concat(body).toString();
      console.log(parsedBody);
      const message = parsedBody.split('=')[1];
      fs.writeFileSync("message.txt", message);
    })
    res.statusCode = 302;
    res.setHeader("Location", "/");
    return res.end();
  }

  // default view
  res.setHeader("Content-Type", "text/html");
  res.write("<html>");
  res.write("<head><title>My first page</title><head>");
  res.write("<body><h1>Hello from the server!</h1></body>");
  res.write("</html>");
  res.end();
});
// listen on port 3000
server.listen(3000);
```
		
This is scary! This is all raw logic, but soon we will use Express.js to hide all that raw logic
		
# Understanding Event Driven Code

The order that the code is executed is not necessarily the order in which the code is written. For example, the code that returns the response object will run before the `message.txt` file is written in the above example. The event listeners aren't dead once the response is sent, with how we wrote it

If we want our event listeners to affect the response object, we would need to move the ending code into the event listener block/scope
		
```JS
req.on('end', () => {
  const parsedBody = Buffer.concat(body).toString();
  console.log(parsedBody);
  const message = parsedBody.split('=')[1];
  fs.writeFileSync("message.txt", message);
  res.statusCode = 302;
  res.setHeader("Location", "/");
  return res.end();
})
```

This is ansyncronous programming, and Node.js uses this concept heavily. Node.js has an internal compacity to manage various event listeners that it automatically attaches to your functions, so that they can be executed asynchronously. Event listener headers are registered, and before anything inside our defined event listeners is executed, it runs the line after the event listeners right away.

In our code, if modified to put the response obeject inside the `end` event listener, it would redirect us to the default view outside our `if` statements. This would make it so that the status code and setting the new header would no longer work, since we got redirected, resulting in errors, because of `res.end()`. We cannot send 2 responses!

If it didn't work this way, it would have to stop and wait for event to resolve, making it so we can't do anything (including receive incoming requests) until the events have been resolved, greatly slowing our server down.

# Blocking vs. Non-Blocking Code

`fs.writeFileSync()` can also been done with `fs.writeFile()`. This is 2 modes of the same method, one is blocking (`wrtieFileSync`) the other is non-blocking (`writeFile`).

**Blocking** code will pause the event loop until the action is resolved, **non-blocking** code will join the event loop and not block it and are used if you need something to finish before responses are sent and other actions are taken. The code would block everything, including incoming requests

That means that it is best to use `fs.writeFile()`. This version also takes a callback, which runs after the action is completed
		
```JS
// The err parameter, if defined, will be used for error handling
// We know we won't have errors here, so the parameter won't be used
fs.writeFile('message.txt', message, (err) => {
  res.statusCode = 302;
  res.setHeader("Location", "/");
  return res.end();
});
```
		
The above would be the best way to write our write file method. It's asynchronous and returns our response after the file is written, which is the most standard way of writing the code. ***Avoid blocking code execution unless you know what you're doing.***

Best way to write the routing for the `/` url:
		
```JS
if (url === "/message" && method === "POST") {
  const body = [];
  req.on('data', (chunk) => {
	  console.log(chunk);
    body.push(chunk);
  });
  req.on('end', () => {
    const parsedBody = Buffer.concat(body).toString();
    console.log(parsedBody);
    const message = parsedBody.split('=')[1];
    fs.writeFile("message.txt", message, err => {
      res.statusCode = 302;
      res.setHeader("Location", "/");
      return res.end();
    });
  })
}
```
		
# Node.js - Behind the Scenes

Node.js uses only 1 JavaScript thread which means only 1 process at a time with no multitasking. So, how is Node.js performant? The event loop!

All of our funcitons have callbacks, and all these callbacks are inside and handled by the event loop Only quick execute code will be handled here, code that takes longer, such as file system code (writing and reading files), will be sent to the worker pool.

The worker pool is kind of detached from the rest of our code, and can then do more heavy lifting on other threads than what the server is running on. Once the wroker is done, it'll trigger the callback for that event, which ends up in the event loop.
		
The event loop is well, a loop. At the beginning of each interation, it checks to see if any timer function need to be executed (`setTimeout` and `setInterval` callbacks). Then, it checks other pending callbacks from code in the worker pool that need to run, since the process has been completed. If there is a backlog of callbacks, the event loop may postpone some callbacks to be run on the next iteration of the loop.

Then, it enter the poll phase. Here, it looks for new input/output events and executes their callbacks immediately. If the callbacks can't be called immediately, then they are defered and registered as a pending callback. It will also check for any timer callback due to the executed input/output code.

Then, it goes through the check phase and runs `setImmediate()` callbacks once any other open callbacks have been finished. Next, all `close` event callbacks are run.

Then, the process exits if there are no open event listeners. The server object has event listeners, so this won't happen while the server is running, unless we make it happen 
			
# Using Modules

There are 2 ways to export functions in Node.js. The first way:
		
```JS
module.exports = functionToExport;
// Now we can require the file that this is in and the function, or whatever we export, will be available to use
```
	
We could encompass all of our routing logic into a separate file, inside a function, then import that funciton to our server and call it.
		
```JS
// routes.js
const fs = require("fs");
const requestHandler = (req, res) => {
  const url = req.url;
  const method = req.method;
  if (url === "/") {
    res.setHeader("Content-Type", "text/html");
    res.write("<html>");
    res.write("<head><title>Enter Message</title><head>");
    res.write("<body><form action='/message' method='POST'><input name='message' type='text'><button type='submit'>Send</button></form></body>");
    res.write("</html>");
    return res.end();
  }
  if (url === "/message" && method === "POST") {
    const body = [];
    req.on('data', (chunk) => {
      console.log(chunk);
      body.push(chunk);
    });
    req.on('end', () => {
      const parsedBody = Buffer.concat(body).toString();
      console.log(parsedBody);
      const message = parsedBody.split('=')[1];
      fs.writeFile("message.txt", message, err => {
        res.statusCode = 302;
        res.setHeader("Location", "/");
        return res.end();
      });
    })
  }
  res.setHeader("Content-Type", "text/html");
  res.write("<html>");
  res.write("<head><title>My first page</title><head>");
  res.write("<body><h1>Hello from the server!</h1></body>");
  res.write("</html>");
  res.end();
}
module.exports = requestHandler;
```

```JS
// server.js
const http = require("http");
const routes = require("./routes");
const server = http.createServer(routes);
server.listen(3000);
```
		
Now we separated our logics: one file to spin up the server, another to handle all the routing. This is good practice and makes a lean and organized workflow.

Another way to export is by exporting multiple things at once inside the exports object
		
```JS
module.exports = {
  handle: handlerFunction
  variable: message
}
```
		
When doing this way, we would have to specifiy what we want to use via dot notation. We can shortcut the above via:
		
```JS
exports.handle = handlerFunciton;
exports.variable = message;
```
